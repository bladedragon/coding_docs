# 消息队列

# Kafka





**Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**

1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

**Zookeeper 在 Kafka 中的作用**

[**Zookeeper 在 Kafka 中的作用**](https://www.jianshu.com/p/a036405f989c)

1. **Broker 注册** ：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到/brokers/ids 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
2. **Topic 注册** ： 在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
3. **负载均衡** ：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。
4. **等等**





## 多副本机制

分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

**好处**

1. Kafka 通过给特定 `Topic `指定多个 `Partition`, 而各个 `Partition `可以分布在不同的 `Broker `上, 这样便能提供比较好的并发能力（负载均衡）。
2. `Partition `可以指定对应的 `Replica `数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。



## 名词介绍

+ `AR`：分区中的所有副本统称为AR

+ `ISR`：所有与leader副本保持一定程度同步的副本（包括Leader）组成ISR

  ISR的伸缩：Kafka在启动的时候会**开启两个与ISR相关的定时任务**,任务会周期性的检测每个分区是否需要缩减其ISR集合.默认值为`5000ms`，当检测到ISR中有失效的副本的时候，就会缩减ISR集合

每个副本对象都具有的属性

+ `HW`： High Watermark/高水位。 是已备份消息位置，HW之前的消息均可被consumer消费
+ `LEO`: Log End Offset/日志末端偏移。是下一条消息写入位置(LEO=10 有9条消息)
+ `LSO`:last stable offset/稳定偏移 。 LSO之前的消息状态都已确认
+ `LW`:Low Watermark 的缩写，俗称“低水位”



- `分区器`:根据键值确定消息应该处于哪个分区中，默认情况下使用**轮询**分区，可以自行实现分区器接口自定义分区逻辑

- `序列化器`:键序列化器和值序列化器，将键和值都转为二进制流 还有反序列化器 将二进制流转为指定类型数据

- `拦截器`:两个方法` doSend()`方法会在序列化之前完成 ; `onAcknowledgement()`方法在消息确认或失败时调用, 可以添加多个拦截器按顺序执行 

  **调用顺序: 拦截器doSend() -> 序列化器 -> 分区器**




## 设计实现





## kafka如何保证消息不丢失不被重复消费

+ 发送端
  + **min.insync.replicas** >1
  +  **acks = all**
+ kafka
  + 多副本机制
+ 消费端

### 消息发送机制

`kafka`的消息发送机制分为同步和异步机制。可以通过`producer.type`属性进行配置。

使用**同步模式**的时候，有三种状态来保证消息的安全生产。可以通过配置`request.required.acks`属性。三个属性分别如下

`0`—表示不进行消息接收是否成功的确认；·
`1`—表示当Leader接收成功时确认；
`-1`—表示Leader和Follower都接收成功时确认；

`acks = 0`的时候，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；

当`acks=1`的时候，只保证leader写入成功。当`leader partition`挂了的时候，数据就有可能发生丢失。

使用**异步模式**的时候，当缓冲区满了，`acks=0`的时候，不需要进行消息接受是否成功的确认，所以会自动清空缓冲池里的消息。

**解决方式**

+ 同步模式下只需要将确认机制设置为`-1`，让消息写入leader和所有的副本，就可以保证消息安全生产。

+ 异步模式下，则需要在配置文件中，将阻塞超时的时间设置为`不限制`。这样生产端会一直阻塞。可以保证数据不丢失
+ 设置`block.on.buffer.full = true`。 这样producer将一直等待缓冲区直至其变为可用。缓冲区满了就阻塞
+ `acks=all`。所有的follwoer都响应了消息就认为消息提交成功。
+ `retries=MAX`。无限重试。
+ `max.in.flight.requests.per.connnection = 1`限制客户端在单个连接上能够发送的未响应的请求的个数。设置为1表示kafka broker在响应请求之前client不能再向broker发送请求了。通过此举可以保证消息的顺序性。

### 消息消费机制

> 关键是保证重复消费后的幂等性

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

kafka的`consumer`模式是**自动提交位移**的。我们只需要在代码逻辑中保证位移提交前消息被处理就行。我们可以关闭自动提交位移，设置`enable.auto.commit`为`false`。自己手动处理消息后提交位移。

### 消息的重复消费如何解决

重复消费的问题，一方面需要消息中间件来进行保证。另一方面需要自己的处理逻辑来保证消息的幂等性。极有可能代码消费了消息，但服务器突然宕机，未来得及提交offset。所以我们可以在代码保证消息消费的幂等性。

至于方法可以通过`redis的原子性`来保证，也可以通过`数据库的唯一id`来保证。

+ 通过版本号/数据快照实现幂等：其实这种方式有点类似于乐观锁的实现方式，就是需要消息中带有此业务当前一个瞬时状态的值，通过这个值与业务当前数据比较来判断是否执行更新操作。
+ 全局唯一ID：所谓的分布式集群中出现的重复消息并行问题，你得保证一个健壮的全局唯一发号器，然后在每次操作之前判断此ID是否已经被别的消费者消费过。
+ 通过数据库的为唯一键实现幂等



### 消息积压问题

> 要么生产者消息数量增加导致的积压；
>
> 要么就是消费者消费变慢导致的消息积压。

1. 生产端：一般当生产端发生积压（Broker正常的情况下）就要查看你的业务逻辑是否有异常的耗时步骤导致的。是否需要改并行化操作等。
2. Broker端：当Broker端发生积压我们首先要查看，消息队列内存使用情况，如果有分区的的话还得看每个分区积压的消息数量差异。当每个分区的消息积压数据量相对均匀的话，我们大致可以认为是流量激增。需要在消费端做优化，或者同时需要增加Broker节点（相当于存储扩容），如果分区加压消息数量差异很大的话（有的队列满了，有的队列可能还是空闲状态），我们这时候就要检查我们的路由转发规则是否合理，
3. 消费端：在使用消息队列的时候大部分的问题都出在消费端，当消费速度小于生产速度很快就会出现积压，导致消息延迟，以至于丢失。这里需要重点说明一点的是，当消费速度小于生产速度的时候，仅增加消费者是没有用处的，因为多个消费者在同一个分区上实际是单线程资源竞争关系（当然还有一些冒险的单队列多消费者并行方式就是：消费者接到消息就ack成功再去处理业务逻辑，这样你就要承受消息丢失的代价），我们需要同时增加Broker上的分区数量才能解决这一问题。

**快速解决方法**

当确定是流量激增的话，我们需要评估是否需要增加资源还是通过限流的方式解决，当短时间大量消息需要处理时，在资源允许的情况下，我们可以新启一批消费者与消息队列，将原来的消费者中的消息直接作为生产者转发到临时应急队列中，这样大概率的能够快速解决消息积压

## 消息丢失问题

> 分mq自己弄丢消息和消费者消费的时候弄丢了

1.**消息者弄丢消息**

+ 关闭自动提交offset，这时问题就转变成解决重复消费如何保证幂等性的问题

2.kafka**弄丢消息**

原因是某个broker宕机，重新选举patition的leader的时候还有数据没同步

+ 给topic设置`replication.factor`参数,值必须大于1，保证每个patition必须有两个副本
+ kafka服务端设置`min.insync.replicas`参数，值必须大于1，要求y一个leader必须感知到至少有一个follower保持联系，保证leader挂了后还有一个follower
+ 在producer端设置`acks=all`参数，要求每条数据必须写入才算成功
+ 在producer端设置`retries=MAX`，写入失败无限重试

## 消息顺序性

kafka保证patiiton级别的消息顺序性

最简单保证消息顺序性的方法：

1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition。



+ **写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性**。

![img](https://img2018.cnblogs.com/blog/1630503/201904/1630503-20190421231840924-2043607136.png)

## Kafka控制器的选举

- 在Kafka集群中会有一个或多个broker，其中有一个broker会被选举为控制器（`KafkaController`），它负责管理整个集群中所有分区和副本的状态等工作。
- 比如当某个分区的`leader`副本出现故障时，由控制器负责为该分区选举新的`leader`副本。再比如当检测到某个分区的`ISR`集合发生变化时，由控制器负责通知所有`broker`更新其元数据信息
- `Kafka Controller`的选举是依赖`Zookeeper`来实现的，在`Kafka`集群中哪个`broker`能够成功创建`/controller`这个临时节点他就可以成为`Kafka Controller`。